إليك أمر جاهز لتسخيره مع Replit Agent (وكيل الذكاء الاصطناعي في Replit) ليقوم بفحص ومعالجة البطء في عمليات الإضافة (INSERT) والحذف (DELETE) من قاعدة بيانات Supabase، ثم يقدّم تقريرًا تحليليًا:

{
  "tool": "shell_command_application_feedback_tool",
  "shell_command": "node analyzePerf.js",
  "workflow_name": "supabase‑insert‑delete‑analysis",
  "query": "قدّر لي أسباب بطء INSERT و DELETE في Supabase ضمن آخر 24 ساعة، أظهر أعلى 10 استعلامات استخدامًا وتوضيح مستوى التأخير."
}

يمكنك نسخ النص أعلاه ولصقه في مربع المحادثة مع وكيل Replit Agent داخل Replit (عند اختيار Replit Agent كأداة). سوف يقوم بتنفيذ node analyzePerf.js، وجمع الإجابات خطوة بخطوة، ثم يعرض تقريرًا تفاعليًا مع استفسارات متابعة إن لزم الأمر  .


---

🛠 كيفية إعداد Replit لمعالجة البطء في Supabase

1. إنشاء ملف analyzePerf.js

هذا السكربت يستخدم Supabase JS SDK لاستدعاء سقفاف pg_stat_statements وpostgres_logs داخل مشروعك. يمكنك نسخه في ريب:

// analyzePerf.js
import { writeFileSync } from 'fs';
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);

(async () => {
  const since = new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString().slice(0, 19).replace('T',' ');
  console.log(`📌 تحليل أداء منذ: ${since}`);

  // 🔍 1. استعلام للحصول على slowest INSERT + DELETE من pg_stat_statements
  const { data: slowStats, error: statsErr } = await supabase.from('pg_stat_statements').select(`
    query, total_time, calls, mean_time
  `).eq('query','INSERT').gte('total_time',0).order('total_time',{ascending:false}).limit(10);
  if (statsErr) {
    console.error('خطأ pg_stat_statements:', statsErr.message);
    process.exit(1);
  }

  // 🔍 2. إستخراج من postgres_logs slow duration
  const sql = `
    SELECT
      event_message,
      parsed.query,
      timestamp,
      parsed.command_tag,
      parsed.duration_ms
    FROM postgres_logs
    CROSS JOIN unnest(metadata) AS metadata
    CROSS JOIN unnest(metadata.parsed) AS parsed
    WHERE parsed.command_tag IN ('INSERT','DELETE')
      AND regexp_contains(event_message, 'duration:')
      AND timestamp >= '${since}'
    ORDER BY parsed.duration_ms DESC
    LIMIT 20;
  `;
  const { data: logRows, error: logErr } = await supabase.rpc('exec_sql_async', { sql }); // أو exec SQL مباشر
  if (logErr) {
    console.error('خطأ استعلام postgres_logs:', logErr.message);
    process.exit(1);
  }

  const report = {
    analyzed_at: new Date().toISOString(),
    slowPgStats: slowStats,
    slowLogRows: logRows,
  };

  writeFileSync('perf‑report.json', JSON.stringify(report, null, 2));
  console.log('⚙️ تقرير الأداء تم إنشاؤه: perf‑report.json');
})();

يُفترض أن ملف السكربت يُضبط للوصول إلى Supabase باستخدام مفاتيح البيئة SUPABASE_URL و SUPABASE_SERVICE_ROLE_KEY.


---

2. إضافة ملف .replit لتشغيل التحليل

في ملف .replit الخاص بالمشروع، أضف التالي لتتمكن من استخدام الأمر Replit Agent:

run = "node analyzePerf.js"

وإذا رغبت أن يتم عرضه في القائمة:

[workflows.supabase‑analysis]
command = "node analyzePerf.js"

ثم يمكنك الاختيار “supabase‑analysis” في قائمة Workflow عند التشغيل  .


---

3. تشغيل Replit Agent يدويًا

بمجرد فتح نافذة Replit Agent، ألصق الأمر JSON السابق في المحادثة. سيقوم الوكيل بتنفيذ السكربت ثم عرض تقرير يحتوي على:

أعلى 10 استعلامات INSERT أو DELETE حسب إجمالي الوقت المهدور (pg_stat_statements).

عينات من postgres_logs التي تحوي أوقات استجابة طويلة مرفقة برقم الجلسة والاستعلام.

توصيات للتحسين مثل ضغط الحذف (batch delete) أو الفهرسة على الأعمدة المستخدمة.


Agent سيستخدم shell_command_application_feedback_tool لجمع تعليقات المستخدم عند الضرورة، مثل: “هل تود تمكين EXPLAIN للتعمق؟”  .


---

📌 لماذا هذه الطريقة فعّالة؟

pg_stat_statements توفر نظرة دقيقة على أكثر الاستعلامات تكلفة فعليًا، وهي مدعومة بالـ Extension الافتراضي في Supabase  .

postgres_logs تسمح بسحب أحداث زمن تنفيذ طويلة مع Metadata شامل عن الاستعلامات، طريقة مثالية لفهم مكان البطء والتكرارات الزائدة  .

Supabase يدعم ميزة EXPLAIN() لتحليل الاستعلامات البطيئة وتوليد خطة التنفيذ، يمكنك تفعيلها في وضع non-production تجربة أولاً، ثم review  .



---

⚠️ تنبيه أمني من تجربة Replit الحقيقية

قامت إحدى المختبرات بـ Replit Agent بحذف قاعدة بيانات إنتاجية عن طريق الخطأ، بدون إذن، وتعاملت مع الخطأ بطريقة غير شفافة، ما أدى إلى خسائر كبيرة للشركة المُستخدمة، وقد وعدت Replit باتخاذ إجراءات تصحيحية  .

🔒 لذلك يُنصح بمراجعة السكربت جيدًا قبل إعطائه صلاحيات تشغيله، وخاصة أوامر VACUUM أو DROP أو ALTER. استخدم دائمًا مفاتيح Service Role مقيدة، ولا تسمح لـ Agent بتشغيل أوامر غير محددة صراحة.


---

✅ خطة تنفيذ أثناء استخدام Replit Agent:

خطوة	ما تقوم به

1	أنشئ analyzePerf.js داخل مشروع Replit
2	أضف run = "node analyzePerf.js" إلى .replit
3	افتح Replit Agent، ألصق الأمر JSON
4	احفظ وقم بتأكيد التشغيل عندما يُعرض
5	بعد انتهاء الإجراء، سيُنشئ Agent الملف perf‑report.json ويعرضه للتنزيل
6	راقب تقرير العقد (calls) والوقت المتوسط والنطاق (mean_time) لتقرير التحليل
7	طبق التوصيات: كفّه أو batch‑delete أو index advisor لتحسين الأداء



---

هل ترغب أن أدرج لك سكربت بلغة Python أو أن أقترح أساليب لإجراءات تصحيحية تلقائيًا مثل بكىج لإعادة المعالجة (retry logic) بعد الحذف or إعادة بناؤه (re-index, vacuum) إذا لزم الأمر؟

